# BasicChatbot

A Streamlit-based chatbot application that leverages LangGraph and LLMs (Large Language Models) to build a stateful, agentic AI chatbot. The app is modular, allowing for easy extension to more use cases and LLM providers.

## Features

- **Streamlit UI**: User-friendly interface for interacting with the chatbot.
- **LLM Integration**: Supports Groq LLMs (Llama3, Gemma2) via API key. Easily select LLM, model, and use case from the sidebar.
- **LangGraph**: Uses LangGraph to build and manage the chatbot's stateful conversation flow.
- **Configurable**: UI and model options are managed via configuration files for easy extensibility.

## How It Works

1. **UI Initialization**: The app loads a Streamlit UI where users select the LLM, model, and use case, and enter their API key.
2. **LLM Setup**: The selected LLM and model are initialized using the provided API key.
3. **Graph Construction**: A LangGraph state graph is built for the selected use case (currently "Basic Chatbot").
4. **Chat Flow**: User messages are processed through the graph, and responses are generated by the LLM.
5. **Display**: The conversation is displayed in a chat-like format in the Streamlit app.

## Project Structure

```
BasicChatbot/
├── app.py
├── requirements.txt
└── src/
    └── langgraphagenticai/
        ├── main.py
        ├── nodes/
        │   └── basic_chatbot_node.py
        ├── LLMS/
        │   └── groqllm.py
        ├── graph/
        │   └── graph_builder.py
        ├── state/
        │   └── state.py
        └── ui/
            ├── uiconfigfile.py
            ├── uiconfigfile.ini
            └── streamlitui/
                ├── loadui.py
                └── display_result.py
```

## Main Components

- **app.py**: Entry point for the Streamlit app. Runs the main application loader.
- **main.py**: Orchestrates UI, LLM setup, graph construction, and result display.
- **ui/streamlitui/loadui.py**: Handles sidebar UI for LLM, model, and use case selection, and API key input.
- **ui/streamlitui/display_result.py**: Streams and displays chat messages in the UI.
- **LLMS/groqllm.py**: Integrates Groq LLMs, handling model and API key setup.
- **graph/graph_builder.py**: Builds the LangGraph state graph for the chatbot.
- **nodes/basic_chatbot_node.py**: Defines the chatbot node logic for processing messages.
- **ui/uiconfigfile.py & uiconfigfile.ini**: Manage UI and model configuration options.

## Setup Instructions

1. **Clone the Repository**

   ```bash
   git clone <your-repo-url>
   cd BasicChatbot
   ```

2. **Install Dependencies**

   Make sure you have Python 3.8+ installed. Then run:

   ```bash
   pip install -r requirements.txt
   ```

3. **Obtain a Groq API Key**

   - Sign up at **[Groq Console](https://console.groq.com/keys)** and generate an API key.

4. **Obtain a Tavily API Key**
   - Sign up at **[Tavily](https://app.tavily.com/home)** and generate an API key

5. **Run the Application**

   ```bash
   streamlit run app.py
   ```

6. **Using the App**

   - In the sidebar, select:
     - LLM: Groq
     - Model: (e.g., llama3-8b-8192)
     - Enter your Groq API key
     - Use Case: Basic Chatbot
   - Enter your message in the chat input box and interact with the AI assistant.

## Configuration

The UI options are managed in `src/langgraphagenticai/ui/uiconfigfile.ini`:

```ini
[DEFAULT]
PAGE_TITLE = LangGraph: Build Stateful Agentic AI graph
LLM_OPTIONS = Groq
USECASE_OPTIONS = Basic Chatbot
GROQ_MODEL_OPTIONS = llama3-8b-8192, llama3-70b-8192, gemma2-9b-it
```

## Requirements

- Python 3.8+
- See `requirements.txt` for all Python dependencies.

## Extending

- Add new use cases by extending the graph builder and node modules.
- Add support for more LLMs by implementing new classes in the `LLMS` directory.

## License

This project is licensed under the MIT License.